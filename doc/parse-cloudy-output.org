
* Parse Cloudy Output: claudia.py
  :LOGBOOK:
  CLOCK: [2011-08-23 Tue 09:40]--[2011-08-23 Tue 10:50] =>  1:10
  CLOCK: [2011-06-27 Mon 23:28]--[2011-06-27 Mon 23:46] =>  0:18
  CLOCK: [2011-06-26 Sun 22:54]--[2011-06-26 Sun 23:23] =>  0:29
  :END:
  :PROPERTIES:
  :tangle:   ../src/claudia.py
  :dir: ~/Work/Nahiely/proplyd-cloudy/src
  :comments: org
  :END:

** Imports

#+srcname: claudia-imports
#+begin_src python
  import numpy
  import argparse
  import string
  import os
#+end_src

** The SmartDict class

+ Taken from the excellent [[http://code.activestate.com/recipes/577590-dictionary-whos-keys-act-like-attributes-as-well/][Python Recipe]] by [[http://code.activestate.com/recipes/users/4174115/][Sunjay Varma]]
+ I will use this as a base class 

#+srcname: claudia-smartdict
#+begin_src python
  class SmartDict(dict):
      """
      Combines the best features of a class and a dict
      """
      def __getattr__(self, name):
          try:
              return self[name]
          except KeyError as e:
              raise AttributeError(e)
      def __setattr__(self, name, value):
          self[name] = value
#+end_src

*** Original description by Sunjay Varma from Python Recipes

Dictionary Who's Keys Act Like Attributes As Well (Python recipe)

Think of this as a JavaScript object. In JavaScript, the objects can be referenced by indexing (e.g. d[name]) or by directly using the dot (.) operator (e.g. d.name).

This is the same concept.

Note to Python 2.4 Users: You will need to change the =except KeyError as e:= line to =except KeyError, (e):=.

#+begin_example
>>> d = Dict(radius=10)
>>> d.radius
10
>>> d.copy = 10
>>> d.copy
<built-in method copy of Dict object at 0x02A056B8>
>>> d["copy"]
10
>>> d.copy()
{'copy': 10, 'radius': 10}
>>> d.fromkeys = lambda x: x * 2
>>> d.fromkeys([10], [10])
{10: [10]}
>>> d["fromkeys"](20)
40
#+end_example

** The class for a Cloudy model


#+srcname: claudia-model-class
#+begin_src python
  class CloudyModel(object):
      """
      A single Cloudy model
  
      >>> from claudia import CloudyModel
      >>> modelname = 'sample'
      >>> CloudyModel.indir = '.'
      >>> m = CloudyModel(modelname)
      >>> m.savecommands
      """
      indir, outdir = "in", "out"
      insuff, outsuff = ".in", ".out"
      # list of save types to skip (problematic to read with genfromtxt)
      skipsaves = ["continuum", "line emissivity"]
      def __init__(self, modelname, **kwargs):
          # Any optional keywords get set as attributes
          # We do this first in case indir or insuff are set
          self.__dict__.update(kwargs)
  
          # Read in the input script
          self.infilepath = os.path.join(self.indir, modelname + self.insuff)
          with open(self.infilepath) as f:
              self._inscript = f.read() 
  
          # Now read in from all the save files
          for savetype, savesuff in find_save_commands(self._inscript):
              savefilepath = os.path.join(self.outdir, modelname + savesuff)
              saveid = savesuff[1:]       # strip the leading dot to make the attribute name
              if not savetype in self.skipsaves:
                  setattr(self, saveid, parse_savefile(savetype, savefilepath))
  
  
#+end_src

** Parsing the save files

It is almost impossible to do this cleanly with output from older versions of Cloudy. At the moment I am resorting to editing the header of the "line emissivity" file to put the header on two lines and delete the final tab and 

#+srcname: claudia-parse-save-file
#+begin_src python
  class CloudySave(object):
      """
      A dataset writen by a Cloudy 'save' command (formerly 'punch')
      """
      def __init__(self, longid, data):
          self.longid = longid
          self._data = data
          # push all the columns up into the top-level namespace for easy access
          for name in self._data.dtype.names:
              setattr(self, name, self._data[name])
  
  SAVETYPES_TWO_LINE_HEADER = [
      "line emissivity",
      ] 
  def parse_savefile(savetype, filepath):
      print "Trying to read ", filepath
      if savetype in SAVETYPES_TWO_LINE_HEADER:
          skip = 1
      else:
          skip = 0
      return CloudySave(savetype, numpy.genfromtxt(filepath, 
                                                   delimiter='\t', 
                                                   skip_header=skip,
                                                   invalid_raise=False,
                                                   names=True))
  
#+end_src



** Parsing the input file

*** List of possibilities for cloudy save files

+ Taken from Hazy1 C10 version 2011/08/14
+ This is nowhere near exhaustive
+ These are checked in turn, so more specific types should come first. 

#+srcname: claudia-types-of-cloudy-save-files
#+begin_src python
  SAVETYPES = [
      "diffuse continuum", 
      "emitted continuum", 
      "fine continuum", 
      "grain continuum", 
      "incident continuum", 
      "interactive continuum", 
      "ionizing continuum", 
      "outward continuum", 
      "raw continuum", 
      "reflected continuum", 
      "transmitted continuum", 
      "two photon continuum", 
      "continuum", 
      "cooling",
      "dr",
      "dynamics",
      "element hydrogen",
      "element helium",
      "element carbon",
      "element nitrogen",
      "element oxygen",
      "element sulfur",
      "element silicon",
      "element iron",
      "heating",
      "line emissivity",
      "line list", 
      "overview",
      "PDR",
      "physical conditions",
      "pressure",
      "radius",
      "source function, spectrum",
      "source function, depth",
      ]
#+end_src

*** Find basic info about the run
    :LOGBOOK:
    CLOCK: [2011-08-20 Sat 18:24]--[2011-08-21 Sun 00:04] =>  5:40
    :END:

#+srcname: claudia-input-parse-basic-info
#+begin_src python

#+end_src


*** Find which save files were written
    :LOGBOOK:
    - Note taken on [2011-08-20 Sat 18:21] \\
      OK, this is just about working now, time to move on
    - Note taken on [2011-08-20 Sat 14:16] \\
      Not sure what we were doing here? What was the use-case of the cut_out function.
    CLOCK: [2011-08-20 Sat 14:16]--[2011-08-20 Sat 18:24] =>  4:08
    CLOCK: [2011-06-28 Tue 13:14]--[2011-06-28 Tue 13:16] =>  0:02
    CLOCK: [2011-06-27 Mon 23:46]--[2011-06-27 Mon 23:46] =>  0:00
    :END:

This originally seemed like a job for regular expressions, but that quickly got out of hand. 

Instead of allowing any type of save file, we use a finite list =SAVETYPES= since that makes the parsing much simpler. The only problem is that Cloudy allows the names to be abbreviated to four letters. 

#+srcname: claudia-get-list-of-save-files
#+begin_src python
  def find_save_commands(s):
      """
      Find all save commands in a Cloudy input file and return a list of [type, file] pairs
  
      >>> find_save_commands('save heating last ".heat"\\nsave cooling last ".cool"')
      [('heating', '.heat'), ('cooling', '.cool')]
      """
      save_commands = [] 
      for line in s.split("\n"):
          found = find_single_save_command(line)
          if found: save_commands.append(found)
      return save_commands or None
      
  
  def find_single_save_command(line):
      """
      Parse single line of a Cloudy input file, looking for a save command
  
      It should work both with C08-style (punch) and C10-style (save) commands:
  
      >>> find_single_save_command('save overview last ".ovr"')
      ('overview', '.ovr')
      >>> find_single_save_command('PUNCH LAST OVERVIEW ".ovr"')
      ('overview', '.ovr')
      >>> find_single_save_command('save over no buffering, last, file=".ovr"')
      ('overview', '.ovr')
      >>> find_single_save_command('save madeupname file=".xyz"')
      (None, '.xyz')
      >>> find_single_save_command('this is not the right command')
  
      Note that the last command prints nothing since it returns None
     
      """
      line = line.lower()
      if line.startswith("save") or line.startswith("punch"):
          assert '"' in line or "'" in line, "No filename given in save/punch command"
          line = cut_out(line, "save")
          line = cut_out(line, "punch")
          if "last" in line:
              line = cut_out(line, "last")
          if '"' in line:
              delim = '"'
          elif "'" in line:
              delim = "'"
          firstpart, savefile = line.split(delim)[:2]
          for savetype in SAVETYPES:
              if look4stringinline(savetype, firstpart):
                  return savetype, savefile
          # failed to find anything
          return None, savefile
      else:
          return None
  
  
#+end_src

*** Utility functions for input parsing 
#+srcname: claudia-input-parse-utilities
#+begin_src python
  def cut_out(s, phrase):
      """
      Returns the input string <s> but with all occurrences of <phrase> deleted
  
      <phrase> should be one or more words, separated by whitespace. Effort is made
      to preserve one space between words, which makes it better than s.replace(phrase, '')
  
      >>> s = 'the quick brown fox, which is the brownest ever, jumped over the lazy dog'
      >>> cut_out(s, 'the')
      'quick brown fox, which is brownest ever, jumped over lazy dog'
      >>> s.replace('the', '')
      ' quick brown fox, which is  brownest ever, jumped over  lazy dog'
  
      Note the extra spaces in the s.replace version
      """
      return ' '.join(map(string.strip, s.split(phrase))).strip()
  
  def look4stringinline(string, line):
      """
      Look for string in line, only comparing the first 4 characters of each word
  
      This is because cloudy does the same.
  
      Case should not matter: 
      >>> look4stringinline('punch pressure', 'PUNC FINAL PRES')
      True
  
      And it is OK to have strings with less than 4 characters:
      >>> look4stringinline('PDR', 'save pdr')
      True
  
      And here is an example that should fail:
      >>> look4stringinline('save whatever', 'save foobar')
      False
  
      """
      words = string.split()
      for word in words:
          if len(word) > 4: word = word[:4] 
          if not word.upper() in line.upper():
              return False
      return True
  
#+end_src

** Mindlessly loading all the data from all the output files

** TODO Dealing with multiple iterations

For simplicity, we first implement only the last iteration. So, either 

1. There is only 1 iteration
2. Only last iteration is saved (using "last" keyword)
3. Or, we just ignore all the earlier ones

Cases 1 and 2 are easiest to deal with, whereas Case 3 requires some preprocessing of the output file before using =numpy.genfromtxt=

There is also:

4. We use all the iterations

Which requires a more complicated structure to hold them. 


** TODO Tests
   :LOGBOOK:
   - Note taken on [2011-08-21 Sun 00:07] \\
     Changed mind - nose has clearer docs than py.test does
   CLOCK: [2011-08-20 Sat 23:40]--[2011-08-21 Sun 16:52] => 17:12
   :END:
The main choices for testing frameworks are 

+ py.test http://doc.pytest.org/
+ nose http://www.somethingaboutorange.com/mrl/projects/nose/

After looking further at the docs, it seems that nose might be better. 

Will also combine with some doctest tests for illustration and testing the documentation. 

*** CANCELED Earlier comment
    CLOSED: [2011-08-21 Sun 00:05]
Of these, py.test seems marginally simpler and has nicer-looking docs. So we will use that. /Now changed my mind/

*** Example data for tests
Put some test data in a top-level directory =testdata= 

*** Unittest tests
    :LOGBOOK:
    CLOCK: [2011-08-23 Tue 10:50]
    :END:

+ [2011-08-23 Tue] With Python version 2.7, it seems that the standard library =unittest= module can now do lots of the things that =nose= can do. So, I will switch to using that since it seems to have better documentation. 


**** Example unittest tests
     :LOGBOOK:
     - Note taken on [2011-08-23 Tue 11:10] \\
       Note that we had to use test_claudia.py not test-claudia.py since the latter is not a valid module name.
     - Note taken on [2011-08-23 Tue 11:02] \\
       First version is a straight port of the nose tests I already had
     :END:
     :PROPERTIES:
     :tangle:   ../src/test_claudia.py
     :END:

#+srcname: unittest-claudia
#+begin_src python
  import unittest
  from claudia import CloudyModel
  
  class ClaudiaTestSample01(unittest.TestCase):
      def setUp(self):
          "set up test fixtures"
          self.model = CloudyModel('sample01', 
                                   indir='../testdata', 
                                   outdir='../testdata',
                                   skipsaves=[])
  
      # def teardown_func():
      #     "tear down test fixtures"
  
      def test_doomed_to_fail(self):
          self.assertEquals(1, 2)
  
      def test_infilepath(self):
          self.assertEquals(self.model.infilepath, '../testdata/sample01.in')
  
#+end_src

**** Run all the unit tests
#+srcname: run-claudia-unitttests
#+begin_src sh :tangle no :results output
  echo "Running unit tests in $(pwd)"
  python -m unittest discover -v 2>&1 
  echo
  echo "Tests last ran $(date)"
#+end_src

#+results: run-claudia-unitttests
#+begin_example
Running unit tests in /Users/will/Work/Nahiely/proplyd-cloudy/src
test_doomed_to_fail (test_claudia.ClaudiaTestSample01) ... FAIL
test_infilepath (test_claudia.ClaudiaTestSample01) ... ok

======================================================================
FAIL: test_doomed_to_fail (test_claudia.ClaudiaTestSample01)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/will/Work/Nahiely/proplyd-cloudy/src/test_claudia.py", line 30, in test_doomed_to_fail
    self.assertEquals(1, 2)
AssertionError: 1 != 2

----------------------------------------------------------------------
Ran 2 tests in 0.369s

FAILED (failures=1)
Trying to read  ../testdata/sample01.con
Trying to read  ../testdata/sample01.phy
Trying to read  ../testdata/sample01.ion_o
Trying to read  ../testdata/sample01.ovr
Trying to read  ../testdata/sample01.lin
Trying to read  ../testdata/sample01.pre
Trying to read  ../testdata/sample01.str
Trying to read  ../testdata/sample01.con
Trying to read  ../testdata/sample01.phy
Trying to read  ../testdata/sample01.ion_o
Trying to read  ../testdata/sample01.ovr
Trying to read  ../testdata/sample01.lin
Trying to read  ../testdata/sample01.pre
Trying to read  ../testdata/sample01.str

Tests last ran Tue Aug 23 13:39:02 CDT 2011
#+end_example


*** Nose tests
    :LOGBOOK:
    CLOCK: [2011-06-28 Tue 13:16]--[2011-06-28 Tue 13:27] =>  0:11
    :END:

**** Notes on using nose
     :LOGBOOK:
     - Note taken on [2011-08-23 Tue 10:38] \\
       It seems I still don't understand how to use the setup and teardown functions. The variables created there are not available in the individual tests. There must be a way round this.
     :END:



**** Example nose tests
     :LOGBOOK:
     - Note taken on [2011-08-23 Tue 11:01] \\
       Turned off tangling here aince we don't use this any more
     :END:
     :PROPERTIES:
     :tangle:   ../src/test-claudia.py
     :END:



#+srcname: test-claudia-nose-examples
#+begin_src python :tangle no
  import nose
  from nose.tools import with_setup
  from claudia import CloudyModel
  
  def setup_func():
      "set up test fixtures"
      CloudyModel.indir = '../testdata'
      model = CloudyModel('sample01')
  
  def teardown_func():
      "tear down test fixtures"
  
  @with_setup(setup_func, teardown_func)
  def test():
      "test destined to fail"
      assert False
  
  @with_setup(setup_func, teardown_func)
  def infilepath_test():
      "test destined to fail"
      assert model.infilepath == '../testdata/sample01.in'
  
#+end_src


**** Run all the nose tests
#+srcname: run-claudia-nosetests
#+begin_src sh :tangle no :results output
  echo "Running nose tests in $(pwd)"
  nosetests 2>&1 
  echo
  echo "Tests last ran $(date)"
#+end_src

#+results: run-claudia-nosetests
#+begin_example
Running nose tests in /Users/will/Work/Nahiely/proplyd-cloudy/src
FE
======================================================================
ERROR: test destined to fail
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/7.1/lib/python2.7/site-packages/nose-1.1.2-py2.7.egg/nose/case.py", line 197, in runTest
    self.test(*self.arg)
  File "/Users/will/Work/Nahiely/proplyd-cloudy/src/test-claudia.py", line 28, in infilepath_test
    assert model.infilepath == '../testdata/sample01.in'
NameError: global name 'model' is not defined

======================================================================
FAIL: test destined to fail
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/7.1/lib/python2.7/site-packages/nose-1.1.2-py2.7.egg/nose/case.py", line 197, in runTest
    self.test(*self.arg)
  File "/Users/will/Work/Nahiely/proplyd-cloudy/src/test-claudia.py", line 23, in test
    assert False
AssertionError

----------------------------------------------------------------------
Ran 2 tests in 0.274s

FAILED (errors=1, failures=1)

Tests last ran Tue Aug 23 10:37:25 CDT 2011
#+end_example




*** Doctest tests
    :LOGBOOK:
    CLOCK: [2011-06-28 Tue 13:27]--[2011-06-28 Tue 13:28] =>  0:01
    :END:

Doctest gets mixed reviews. It is the simplest of all to use and seems to be fine for illustrating how to call functions and to make sure that the documentation is in sync with the code. Lots of people warn that it should not replace proper unit testing though. 

**** DONE Run all the doctest tests in claudia.py
     CLOSED: [2011-06-28 Tue 14:24]
     :LOGBOOK:
     - Note taken on [2011-08-20 Sat 14:13] \\
       Print the time that test was last run
     - Note taken on [2011-06-28 Tue 14:24] \\
       Re-factored to be standalone test
     :END:


#+srcname: claudia-doctests
#+begin_src python :tangle no :results output
  import doctest
  import claudia
  from datetime import datetime
  doctest.testmod(claudia)
  print 'Tests run ', datetime.now()
#+end_src

#+results: claudia-doctests
: Tests run  2011-08-20 18:12:07.929649



* TODO Makefile

How can we automate the tangling and generating the HTML docs?

* Export template						   :noexport:
#+TITLE:     Parse Cloudy Output with claudia.py
#+AUTHOR:    William Henney
#+EMAIL:     whenney@gmail.com
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:nil toc:t \n:nil @:t ::t |:t ^:{} -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:   
#+LINK_HOME: 
#+XSLT:
